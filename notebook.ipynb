{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "#import torch\n",
    "from hummingbird.ml import convert, load #https://github.com/microsoft/hummingbird\n",
    "# hummingbird is usefull when you have trained model and you need to speed up prediction step\n",
    "# it doesn't have nmf\n",
    "\n",
    "from utils import load_file\n",
    "from utils import DataResize\n",
    "from utils import DeltaF\n",
    "from utils import NMF_CV, NMF_CV_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data address\n",
    "h5_add = 'I:/P6 Project/Analyses/Triple mutation/210127_P6_scn2a_triplet/h5/run3_LED17mA-1h56min small obj.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data = load_file(add=h5_add, key_name = 'GroupHierarchy.Groups.Datasets')\n",
    "working_data = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizing data \n",
    "data_resized = DataResize(data=working_data, dim=(128,128)).transform()\n",
    "working_data = data_resized\n",
    "print(f'new data size: {data_resized.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "\n",
    "# (1) check variance in the video\n",
    "plt.imshow(np.var(working_data, axis=0))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "n, p1, p2 = working_data.shape\n",
    "\n",
    "# initialize class with user given threshold\n",
    "var_feature = VarianceThreshold(threshold=10000)\n",
    "\n",
    "# fit on data\n",
    "var_feature.fit(working_data.reshape(n, p1 * p2))\n",
    "\n",
    "# transform data\n",
    "feature_selected = var_feature.transform(working_data.reshape(n, p1 * p2))\n",
    "working_data = feature_selected\n",
    "\n",
    "print(f'selected feature shape for given threshold: {feature_selected.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstructing back data\n",
    "data_rec = var_feature.inverse_transform(working_data)\n",
    "\n",
    "# reshape back data to 3d tensor\n",
    "data_rec = data_rec.reshape(n, p1, p2)\n",
    "working_data = data_rec\n",
    "\n",
    "print(f'reconstructed data size: {data_rec.shape} \\n\\n\\n')\n",
    "print('HINT: PLEASE NOTICE THAT, X with columns of zeros inserted where features would have been removed by transform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to get selected indices\n",
    "# var_feature.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# claculate detalf/f0\n",
    "n, p1 = working_data.shape \n",
    "data_deltaf = DeltaF(data=working_data, prct = 20).run_on_matrix()\n",
    "working_data = data_deltaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "# run NMF_CV normal\n",
    "start_time = time.clock()\n",
    "train_error, test_error = NMF_CV_loop(data = data_deltaf, rank_range=np.arange(5,80,5), replicates=6)\n",
    "print(f'execution time: {np.rint(time.clock() - start_time)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run in parallel with shared memory\n",
    "start_time = time.clock()\n",
    "nmf_cv_results = Parallel(n_jobs=8, verbose=1, \n",
    "                                 require='sharedmem')(delayed(NMF_CV)(data = data_deltaf, \n",
    "                                                                      rank=i, \n",
    "                                                                      replicates=j) for j in range(10) for i in range(70, 75, 5))\n",
    "print(f'execution time: {np.rint(time.clock() - start_time)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# run in parallel\n",
    "start_time = time.clock()\n",
    "nmf_cv_results = Parallel(n_jobs=4, verbose=5, \n",
    "                                 backend = 'loky')(delayed(NMF_CV)(data = fp, \n",
    "                                                                      rank=i, \n",
    "                                                                      replicates=j) for j in range(1) for i in range(70, 75, 5))\n",
    "print(f'execution time: {np.rint(time.clock() - start_time)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 3130)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_delta_f = np.load(\"test_data.npy\")\n",
    "data_delta_f.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
